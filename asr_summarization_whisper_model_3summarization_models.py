# -*- coding: utf-8 -*-
"""ASR_Summarization_Whisper_model_3summarization_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PKoIClrWPVRu7y86DXZXKanivprrjq5W
"""

!pip install --upgrade pytube
!pip install --upgrade youtube-dl
!pip install --upgrade yt-dlp

!pip install pytube

!pip install ffprobe

import yt_dlp

ydl_opts = {
    'format': 'bestaudio[ext=webm]',  # Select the best audio format with .webm extension
    'outtmpl': 'downloaded_audio.%(ext)s',  # Output filename with the appropriate extension
    'postprocessors': [{
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'webm',  # Ensure the audio is in webm format
    }],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(['https://www.youtube.com/watch?v=QB1ZqOxfmlw&ab_channel=Intro%C3%A0l%27apprentissageautomatique-ULaval'])

import torch
device = "cuda" if torch.cuda.is_available() else "cpu"

device

! ffmpeg -i downloaded_audio.webm -vn -ar 16000 -ac 1 -f wav downloaded_audio.wav

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("automatic-speech-recognition", model="openai/whisper-base",device=device)

dataset = "/content/downloaded_audio.wav"

import librosa

dataset = "/content/downloaded_audio.wav"

stream = librosa.stream(
    dataset,
    block_length=30,
    frame_length=16000,
    hop_length=16000,
)

import soundfile as sf
for i,speech in enumerate(stream):
  sf.write(f'{i}.wav',speech,16000)



"""**Chunk Transcription(4 chunks)**"""

audio = []
for i in range(4):
  audio.append(f"/content/{i}.wav")

audio

transcription = pipe(audio)

full_transcription = ""
for i in transcription:
  full_transcription += i['text']

full_transcription



"""[model with more than 1024 tokens](https://discuss.huggingface.co/t/which-summarization-model-of-huggingface-supports-more-than-1024-tokens-which-model-is-more-suitable-for-programming-related-articles/25095) the model used contains unlimited input length ?"""

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("text2text-generation", model="abertsch/unlimiformer-bart-govreport-alternating")

summarized_text = pipe(full_transcription)

summarized_text[0]["generated_text"]

# Use a pipeline as a high-level helper
from transformers import pipeline

summarizer = pipeline("text2text-generation", model="allenai/PRIMERA")

summarized_text = summarizer(full_transcription)

summarized_text[0]["generated_text"]

summarization = pipeline('summarization',model="sshleifer/distilbart-cnn-12-6")

summarized_text = summarization(full_transcription)

summarized_text[0]['summary_text']

num_iters = int(len(full_transcription)/1000)
summarized_text = []
for i in range(0, num_iters + 1):
  start = 0
  start = i * 1000
  end = (i + 1) * 1000
  print("input text \n" + full_transcription[start:end])
  out = summarization(full_transcription[start:end], min_length = 5, max_length=20)
  out = out[0]
  out = out['summary_text']
  print("Summarized text\n"+out)
  summarized_text.append(out)

print(summarized_text)

